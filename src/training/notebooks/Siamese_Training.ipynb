{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Siamese TCN Training - Full 22-Player Context\n",
                "\n",
                "This notebook trains a Siamese TCN to learn embeddings for play similarity using **all 22 players**.\n",
                "\n",
                "**Updates for full 22-player context:**\n",
                "- Input: (22, 2, T) → flattened to (44, T) for 22 players × 2 coords\n",
                "- Model: input_channels=44 instead of 22\n",
                "- Distance normalization: Auto-computed from 95th percentile"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Upload training files to Colab:\n",
                "# - aligned_scenes.pkl\n",
                "# - training_pairs.pkl\n",
                "\n",
                "import torch\n",
                "import torch.nn as nn\n",
                "import torch.optim as optim\n",
                "from torch.utils.data import Dataset, DataLoader\n",
                "import numpy as np\n",
                "import pickle\n",
                "import os\n",
                "from tqdm import tqdm"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Configuration\n",
                "DATA_PATH = 'aligned_scenes.pkl'\n",
                "LABELS_PATH = 'training_pairs.pkl'\n",
                "BATCH_SIZE = 32\n",
                "LEARNING_RATE = 1e-3\n",
                "EPOCHS = 20\n",
                "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
                "\n",
                "print(f\"Using device: {DEVICE}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class SoccerSceneDataset(Dataset):\n",
                "    def __init__(self, scenes_path, labels_path):\n",
                "        print(f\"Loading scenes from {scenes_path}...\")\n",
                "        with open(scenes_path, 'rb') as f:\n",
                "            self.scenes = pickle.load(f)\n",
                "            \n",
                "        print(f\"Loading labels from {labels_path}...\")\n",
                "        with open(labels_path, 'rb') as f:\n",
                "            self.pairs = pickle.load(f)\n",
                "        \n",
                "        # Compute distance statistics for normalization\n",
                "        distances = [p['distance'] for p in self.pairs]\n",
                "        self.dist_norm_factor = np.percentile(distances, 95)\n",
                "        \n",
                "        print(f\"Loaded {len(self.scenes)} scenes and {len(self.pairs)} training pairs\")\n",
                "        print(f\"Distance stats: min={np.min(distances):.1f}, max={np.max(distances):.1f}, \"\n",
                "              f\"mean={np.mean(distances):.1f}, 95th percentile={self.dist_norm_factor:.1f}\")\n",
                "            \n",
                "    def __len__(self):\n",
                "        return len(self.pairs)\n",
                "    \n",
                "    def __getitem__(self, idx):\n",
                "        pair = self.pairs[idx]\n",
                "        \n",
                "        idx_a = pair['index_a']\n",
                "        idx_b = pair['index_b']\n",
                "        dist_target = pair['distance']\n",
                "        \n",
                "        # Get tensors (22, 2, T) - all 22 players (11 attacking + 11 defending)\n",
                "        tensor_a = self.scenes[idx_a]['scene_tensor']  # (22, 2, 150)\n",
                "        tensor_b = self.scenes[idx_b]['scene_tensor']  # (22, 2, 150)\n",
                "        \n",
                "        # Fill NaNs with 0\n",
                "        tensor_a = np.nan_to_num(tensor_a, nan=0.0)\n",
                "        tensor_b = np.nan_to_num(tensor_b, nan=0.0)\n",
                "        \n",
                "        # Reshape to (44, T) for model input\n",
                "        # (22, 2, T) -> (44, T) by flattening player dimension\n",
                "        feat_a = tensor_a.reshape(-1, tensor_a.shape[2])  # (44, 150)\n",
                "        feat_b = tensor_b.reshape(-1, tensor_b.shape[2])  # (44, 150)\n",
                "        \n",
                "        # Normalize distance using 95th percentile\n",
                "        dist_target = dist_target / self.dist_norm_factor\n",
                "        \n",
                "        return (\n",
                "            torch.tensor(feat_a, dtype=torch.float32),\n",
                "            torch.tensor(feat_b, dtype=torch.float32),\n",
                "            torch.tensor(dist_target, dtype=torch.float32)\n",
                "        )"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Model Architecture"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "class GatedTCNBlock(nn.Module):\n",
                "    def __init__(self, in_channels, out_channels, kernel_size, dilation, dropout=0.2):\n",
                "        super().__init__()\n",
                "        self.conv_f = nn.Conv1d(in_channels, out_channels, kernel_size, \n",
                "                                padding=(kernel_size-1)*dilation//2, \n",
                "                                dilation=dilation)\n",
                "        self.conv_g = nn.Conv1d(in_channels, out_channels, kernel_size, \n",
                "                                padding=(kernel_size-1)*dilation//2, \n",
                "                                dilation=dilation)\n",
                "        self.dropout = nn.Dropout(dropout)\n",
                "        \n",
                "        # Residual connection\n",
                "        self.downsample = nn.Conv1d(in_channels, out_channels, 1) if in_channels != out_channels else None\n",
                "\n",
                "    def forward(self, x):\n",
                "        f = torch.tanh(self.conv_f(x))\n",
                "        g = torch.sigmoid(self.conv_g(x))\n",
                "        out = f * g\n",
                "        out = self.dropout(out)\n",
                "        \n",
                "        res = x if self.downsample is None else self.downsample(x)\n",
                "        return out + res\n",
                "\n",
                "class SiameseTCN(nn.Module):\n",
                "    def __init__(self, input_channels=44, hidden_channels=32, embedding_dim=64):\n",
                "        super().__init__()\n",
                "        \n",
                "        # TCN Backbone\n",
                "        self.tcn = nn.Sequential(\n",
                "            GatedTCNBlock(input_channels, hidden_channels, kernel_size=3, dilation=1),\n",
                "            GatedTCNBlock(hidden_channels, hidden_channels, kernel_size=3, dilation=2),\n",
                "            GatedTCNBlock(hidden_channels, hidden_channels, kernel_size=3, dilation=4),\n",
                "            GatedTCNBlock(hidden_channels, hidden_channels, kernel_size=3, dilation=8)\n",
                "        )\n",
                "        \n",
                "        # Embedding Head\n",
                "        self.pool = nn.AdaptiveAvgPool1d(1)\n",
                "        self.fc = nn.Sequential(\n",
                "            nn.Linear(hidden_channels, embedding_dim),\n",
                "            nn.LayerNorm(embedding_dim)\n",
                "        )\n",
                "        \n",
                "    def forward_one(self, x):\n",
                "        # x: (B, 44, T) - batch of flattened scene tensors (22 players × 2 coords)\n",
                "        x = self.tcn(x)\n",
                "        x = self.pool(x).squeeze(-1)  # (B, hidden)\n",
                "        x = self.fc(x)\n",
                "        return x\n",
                "    \n",
                "    def forward(self, x1, x2):\n",
                "        emb1 = self.forward_one(x1)\n",
                "        emb2 = self.forward_one(x2)\n",
                "        return emb1, emb2"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Training Loop"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Create dataset and loader\n",
                "dataset = SoccerSceneDataset(DATA_PATH, LABELS_PATH)\n",
                "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n",
                "\n",
                "# Initialize model\n",
                "model = SiameseTCN(input_channels=44, hidden_channels=32, embedding_dim=64).to(DEVICE)\n",
                "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
                "criterion = nn.MSELoss()\n",
                "\n",
                "print(f\"Model has {sum(p.numel() for p in model.parameters())} parameters\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Training loop\n",
                "for epoch in range(EPOCHS):\n",
                "    model.train()\n",
                "    total_loss = 0\n",
                "    \n",
                "    pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{EPOCHS}\")\n",
                "    for batch_idx, (feat_a, feat_b, dist_target) in enumerate(pbar):\n",
                "        feat_a = feat_a.to(DEVICE)\n",
                "        feat_b = feat_b.to(DEVICE)\n",
                "        dist_target = dist_target.to(DEVICE)\n",
                "        \n",
                "        # Forward pass\n",
                "        emb_a, emb_b = model(feat_a, feat_b)\n",
                "        \n",
                "        # Compute Euclidean distance\n",
                "        pred_dist = torch.norm(emb_a - emb_b, p=2, dim=1)\n",
                "        \n",
                "        # Loss\n",
                "        loss = criterion(pred_dist, dist_target)\n",
                "        \n",
                "        # Backward\n",
                "        optimizer.zero_grad()\n",
                "        loss.backward()\n",
                "        optimizer.step()\n",
                "        \n",
                "        total_loss += loss.item()\n",
                "        pbar.set_postfix({'loss': loss.item()})\n",
                "    \n",
                "    avg_loss = total_loss / len(dataloader)\n",
                "    print(f\"Epoch {epoch+1}/{EPOCHS}, Average Loss: {avg_loss:.4f}\")\n",
                "\n",
                "print(\"Training complete!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Save Model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Save model weights\n",
                "torch.save(model.state_dict(), 'siamese_tcn_full.pth')\n",
                "print(\"Model saved to siamese_tcn_full.pth\")\n",
                "\n",
                "# Download this file and use it with the index pipeline"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}